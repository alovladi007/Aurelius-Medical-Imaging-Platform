{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Visualization and Analysis\n",
    "\n",
    "This notebook visualizes and analyzes quantitative features extracted from histopathology images.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Features\n",
    "\n",
    "Load the quantitative features extracted from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\n",
    "features_path = Path('../experiments/features/features.parquet')\n",
    "\n",
    "if features_path.exists():\n",
    "    df = pd.read_parquet(features_path)\n",
    "    print(f\"Loaded {len(df)} samples with {len(df.columns)} features\")\n",
    "    print(f\"\\nColumns: {list(df.columns[:20])}...\")\n",
    "else:\n",
    "    print(f\"Features file not found at {features_path}\")\n",
    "    print(\"Please run: python scripts/extract_quant_features.py first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with labels if needed\n",
    "if 'label' not in df.columns:\n",
    "    # Load splits to get labels\n",
    "    train_df = pd.read_csv('../data/splits/train.csv')\n",
    "    df = df.merge(train_df[['image_path', 'label']], on='image_path', how='left')\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Types\n",
    "\n",
    "Separate features by type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types\n",
    "color_features = [c for c in df.columns if c.startswith('color_')]\n",
    "texture_features = [c for c in df.columns if c.startswith('glcm_') or c.startswith('lbp_')]\n",
    "morph_features = [c for c in df.columns if c.startswith('morph_')]\n",
    "freq_features = [c for c in df.columns if c.startswith('freq_')]\n",
    "deep_features = [c for c in df.columns if c.startswith('deep_feature_')]\n",
    "\n",
    "print(f\"Color features: {len(color_features)}\")\n",
    "print(f\"Texture features: {len(texture_features)}\")\n",
    "print(f\"Morphological features: {len(morph_features)}\")\n",
    "print(f\"Frequency features: {len(freq_features)}\")\n",
    "print(f\"Deep features: {len(deep_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation with Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations with label\n",
    "feature_cols = color_features + texture_features + morph_features + freq_features\n",
    "correlations = df[feature_cols + ['label']].corr()['label'].drop('label').sort_values(ascending=False)\n",
    "\n",
    "# Plot top correlations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Top positive correlations\n",
    "top_positive = correlations.head(15)\n",
    "axes[0].barh(range(len(top_positive)), top_positive.values)\n",
    "axes[0].set_yticks(range(len(top_positive)))\n",
    "axes[0].set_yticklabels(top_positive.index, fontsize=8)\n",
    "axes[0].set_xlabel('Correlation with Label')\n",
    "axes[0].set_title('Top 15 Positive Correlations')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Top negative correlations\n",
    "top_negative = correlations.tail(15)\n",
    "axes[1].barh(range(len(top_negative)), top_negative.values)\n",
    "axes[1].set_yticks(range(len(top_negative)))\n",
    "axes[1].set_yticklabels(top_negative.index, fontsize=8)\n",
    "axes[1].set_xlabel('Correlation with Label')\n",
    "axes[1].set_title('Top 15 Negative Correlations')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distributions by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of top features\n",
    "top_features = correlations.abs().sort_values(ascending=False).head(9).index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    for class_id in [0, 1]:\n",
    "        class_data = df[df['label'] == class_id][feature]\n",
    "        axes[idx].hist(class_data, bins=30, alpha=0.5, \n",
    "                      label=f\"Class {class_id}\", density=True)\n",
    "    \n",
    "    axes[idx].set_title(feature, fontsize=10)\n",
    "    axes[idx].set_xlabel('Value')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation heatmap for top features\n",
    "top_n = 20\n",
    "top_features_for_heatmap = correlations.abs().sort_values(ascending=False).head(top_n).index.tolist()\n",
    "\n",
    "corr_matrix = df[top_features_for_heatmap].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title(f'Feature Correlation Heatmap (Top {top_n} Features)')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on classical features\n",
    "X = df[feature_cols].fillna(0)\n",
    "y = df['label']\n",
    "\n",
    "# Standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# PCA scatter\n",
    "for class_id in [0, 1]:\n",
    "    mask = y == class_id\n",
    "    axes[0].scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "                   label=f\"Class {class_id}\", alpha=0.6, s=20)\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "axes[0].set_title('PCA of Classical Features')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Explained variance\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_scaled)\n",
    "cumsum = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "axes[1].plot(range(1, len(cumsum) + 1), cumsum)\n",
    "axes[1].set_xlabel('Number of Components')\n",
    "axes[1].set_ylabel('Cumulative Explained Variance')\n",
    "axes[1].set_title('PCA Explained Variance')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].axhline(y=0.95, color='r', linestyle='--', label='95% variance')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE (on a subset for speed)\n",
    "n_samples = min(1000, len(X_scaled))\n",
    "indices = np.random.choice(len(X_scaled), n_samples, replace=False)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_scaled[indices])\n",
    "y_subset = y.iloc[indices]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for class_id in [0, 1]:\n",
    "    mask = y_subset == class_id\n",
    "    plt.scatter(X_tsne[mask, 0], X_tsne[mask, 1], \n",
    "               label=f\"Class {class_id}\", alpha=0.6, s=20)\n",
    "\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('t-SNE of Classical Features')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP (if deep features available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP on deep features if available\n",
    "if len(deep_features) > 0:\n",
    "    X_deep = df[deep_features].fillna(0)\n",
    "    \n",
    "    # UMAP\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    X_umap = reducer.fit_transform(X_deep)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for class_id in [0, 1]:\n",
    "        mask = y == class_id\n",
    "        plt.scatter(X_umap[mask, 0], X_umap[mask, 1], \n",
    "                   label=f\"Class {class_id}\", alpha=0.6, s=20)\n",
    "    \n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    plt.title('UMAP of Deep Features')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No deep features found. Extract features with trained model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple Random Forest to get feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Use a subset of features to avoid overfitting\n",
    "selected_features = correlations.abs().sort_values(ascending=False).head(30).index.tolist()\n",
    "X_selected = df[selected_features].fillna(0)\n",
    "\n",
    "# Train RF\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf.fit(X_selected, y)\n",
    "\n",
    "# Get feature importance\n",
    "importances = pd.Series(rf.feature_importances_, index=selected_features).sort_values(ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "importances.head(20).plot(kind='barh')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 20 Most Important Features (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics by Feature Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature types\n",
    "feature_types = {\n",
    "    'Color': color_features,\n",
    "    'Texture': texture_features,\n",
    "    'Morphology': morph_features,\n",
    "    'Frequency': freq_features,\n",
    "}\n",
    "\n",
    "type_stats = []\n",
    "\n",
    "for ftype, features in feature_types.items():\n",
    "    if len(features) > 0:\n",
    "        # Average absolute correlation with label\n",
    "        avg_corr = correlations[features].abs().mean()\n",
    "        max_corr = correlations[features].abs().max()\n",
    "        \n",
    "        type_stats.append({\n",
    "            'Feature Type': ftype,\n",
    "            'Count': len(features),\n",
    "            'Avg |Correlation|': avg_corr,\n",
    "            'Max |Correlation|': max_corr,\n",
    "        })\n",
    "\n",
    "stats_df = pd.DataFrame(type_stats)\n",
    "print(\"\\nFeature Type Statistics:\")\n",
    "print(stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- Features have been successfully extracted and analyzed\n",
    "- Clear separation between classes is visible in reduced dimensions\n",
    "- Multiple feature types contribute to classification\n",
    "- Ready for advanced modeling and interpretation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
