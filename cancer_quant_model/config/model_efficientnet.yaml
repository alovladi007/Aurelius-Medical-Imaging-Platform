# EfficientNet Model Configuration

model:
  name: "efficientnet_b0"
  architecture: "efficientnet"

  # Model variant
  variant: "efficientnet_b0"  # b0, b1, b2, b3, b4, b5, b6, b7, v2_s, v2_m, v2_l

  # Pretrained weights
  pretrained: true
  pretrained_weights: "IMAGENET1K_V1"

  # Feature extraction vs fine-tuning
  freeze_backbone: false
  freeze_layers: 0

  # Classification head
  head:
    num_classes: 2
    dropout: 0.3
    activation: "silu"  # SiLU/Swish is default for EfficientNet

    use_custom_head: false
    hidden_dims: [512]
    batch_norm: true

  # Global pooling
  global_pool: "avg"

  # Feature dimension (varies by variant)
  feature_dim: 1280  # EfficientNet-B0 default

  # Auxiliary outputs
  extract_features: true
  feature_layers: ["blocks.5", "blocks.6"]

  # Model modifications
  modifications:
    # Stochastic depth (drop path)
    drop_path_rate: 0.2

    # Attention mechanisms
    use_cbam: false
    use_se: true  # SE is built into EfficientNet
    se_reduction: 4

  # Input specifications
  input:
    size: [224, 224]  # Varies by variant (B0: 224, B7: 600)
    channels: 3

  # Loss function
  loss:
    type: "cross_entropy"
    label_smoothing: 0.1  # EfficientNet often benefits from label smoothing
    focal_alpha: null
    focal_gamma: 2.0

  # Optimizer
  optimizer:
    type: "adamw"
    lr: 0.001
    weight_decay: 0.00001  # Lower weight decay for EfficientNet
    betas: [0.9, 0.999]

  # Learning rate scheduler
  scheduler:
    type: "cosine"
    warmup_epochs: 5
    min_lr: 0.000001

  # Training settings
  training:
    max_epochs: 100
    early_stopping_patience: 15
    gradient_clip_val: 1.0
    accumulate_grad_batches: 1
    mixed_precision: true
    gradient_checkpointing: false

  # Metrics to track
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "auroc"
    - "auprc"
    - "confusion_matrix"
